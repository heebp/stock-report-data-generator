{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet langchain-teddynote bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.llms import GPT4All\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.callbacks import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "RAG\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"RAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bs4.element.SoupStrainer at 0x1c598d2b440>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs4.SoupStrainer(\n",
    "    \"div\",\n",
    "    attrs={\"class\": [\"newsct_article _article_body\", \"media_end_head_title\"]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://n.news.naver.com/mnews/article/003/0012813373 - 문서의 수: 1\n",
      "URL: https://n.news.naver.com/mnews/article/050/0000080411 - 문서의 수: 1\n"
     ]
    }
   ],
   "source": [
    "# 뉴스기사 내용을 로드하고, 청크로 나누고, 인덱싱합니다.\n",
    "\n",
    "# 뉴스 데이터를 배열로 받는다고 가정합니다.\n",
    "news_data = [\n",
    "    \"https://n.news.naver.com/mnews/article/003/0012813373\",\n",
    "    \"https://n.news.naver.com/mnews/article/050/0000080411\",\n",
    "    # 추가적인 URL을 여기에 추가하세요\n",
    "]\n",
    "\n",
    "# 결과를 저장할 빈 리스트를 생성합니다.\n",
    "all_splits = []\n",
    "\n",
    "# news_data에 있는 URL을 반복적으로 처리합니다.\n",
    "for news_url in news_data:\n",
    "    # 각 뉴스 URL에 대해 WebBaseLoader를 설정합니다.\n",
    "    loader = WebBaseLoader(\n",
    "        web_paths=(news_url,),\n",
    "        bs_kwargs=dict(\n",
    "            parse_only=bs4.SoupStrainer(\n",
    "                \"div\",\n",
    "                attrs={\"class\": [\"newsct_article _article_body\", \"media_end_head_title\"]},\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    # 문서 로드\n",
    "    docs = loader.load()\n",
    "    print(f\"URL: {news_url} - 문서의 수: {len(docs)}\")\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    all_splits.extend(splits)\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=GPT4AllEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# prompt = PromptTemplate.from_template(\n",
    "#     \"\"\"당신은 질문-답변(Question-Answering)을 수행하는 친절한 AI 어시스턴트입니다. 당신의 임무는 주어진 문맥(context) 에서 주어진 질문(question) 에 답하는 것입니다.\n",
    "# 검색된 다음 문맥(context) 을 사용하여 질문(question) 에 답하세요. 만약, 주어진 문맥(context) 에서 답을 찾을 수 없다면, 답을 모른다면 `주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다` 라고 답하세요.\n",
    "# 한글로 답변해 주세요. 단, 기술적인 용어나 이름은 번역하지 않고 그대로 사용해 주세요.\n",
    "\n",
    "# #Question: \n",
    "# {question} \n",
    "\n",
    "# #Context: \n",
    "# {context} \n",
    "\n",
    "# #Answer:\"\"\"\n",
    "# )\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"당신은 최신 금융 동향을 분석하고 제공하는 친절한 AI 어시스턴트입니다. 당신의 임무는 주어진 문맥(context)을 바탕으로 금융 시장에 대한 동향을 전달하는 것입니다.\n",
    "검색된 다음 문맥(context)을 사용하여 최신 금융 시장 동향을 요약해 주세요. 만약, 주어진 문맥(context)에서 동향을 찾을 수 없다면, `주어진 정보에서 금융 시장 동향에 대한 정보를 찾을 수 없습니다`라고 답하세요.\n",
    "한글로 답변해 주세요. 단, 기술적인 용어나 이름은 번역하지 않고 그대로 사용해 주세요.\n",
    "\n",
    "#문맥(Context): \n",
    "{context} \n",
    "\n",
    "#금융 시장 동향 요약:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEVE_Korean_Instruct = \"C:/Users/David/AppData/Local/nomic.ai/GPT4All/EEVE-Korean-Instruct-10.8B-v1.0-Q4_0.gguf\"  # 원하는 로컬 파일 경로로 대체하세요\n",
    "gpt4all_falcon = \"C:/Users/David/AppData/Local/nomic.ai/GPT4All/gpt4all-falcon-newbpe-q4_0.gguf\"\n",
    "llama3_8b =\"C:/Users/David/AppData/Local/nomic.ai/GPT4All/Meta-Llama-3-8B-Instruct.Q4_0.gguf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GPT4All(\n",
    "    model=gpt4all_falcon,\n",
    "    # backend=\"gpu\",  # GPU 설정\n",
    "    streaming=True,  # 스트리밍 설정\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],  # 콜백 설정\n",
    ")\n",
    "\n",
    "# 체인 생성\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: The prompt size exceeds the context window size and cannot be processed.ERROR: The prompt size exceeds the context window size and cannot be processed."
     ]
    }
   ],
   "source": [
    "answer = rag_chain.stream(\"금융 시장 동향을 요약해주세요.\")\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sure, here's a sample answer to the question \"What is your favorite Korean dish?\" in Korean:\n",
      "\n",
      "밥은 이야기로 맛집하면 좋아요하면 지발지로 맛집하면 좋아요하면 지발지로 맛집하면 좋아요하면 지발지로 맛집하면 좋아요하면 지발지로 맛집하면 좋아요하면 지발지로 맛집하면 좋아"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nSure, here\\'s a sample answer to the question \"What is your favorite Korean dish?\" in Korean:\\n\\n밥은 이야기로 맛집하면 좋아요하면 지발지로 맛집하면 좋아요하면 지발지로 맛집하면 좋아요하면 지발지로 맛집하면 좋아요하면 지발지로 맛집하면 좋아요하면 지발지로 맛집하면 좋아'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm(\"한국어로 답변할 수 있습니다?\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt4all",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
