{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain_text_splitters in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: langchain in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: langchain-chroma in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (0.1.4)\n",
      "Requirement already satisfied: langchain-teddynote in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (0.0.34)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langchain_text_splitters) (0.3.8)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langchain-community) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langchain-community) (3.10.8)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langchain-community) (0.1.130)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langchain-community) (2.5.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langchain-community) (8.5.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langchain-chroma) (0.5.11)\n",
      "Requirement already satisfied: fastapi<1,>=0.95.2 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langchain-chroma) (0.115.0)\n",
      "Requirement already satisfied: kiwipiepy in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langchain-teddynote) (0.18.1)\n",
      "Requirement already satisfied: konlpy in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langchain-teddynote) (0.6.0)\n",
      "Requirement already satisfied: rank-bm25 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langchain-teddynote) (0.2.2)\n",
      "Requirement already satisfied: pinecone-client[grpc] in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langchain-teddynote) (5.0.1)\n",
      "Requirement already satisfied: pinecone-text in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langchain-teddynote) (0.9.0)\n",
      "Requirement already satisfied: olefile in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langchain-teddynote) (0.47)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langchain-teddynote) (1.17.0)\n",
      "Requirement already satisfied: openai in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langchain-teddynote) (1.51.0)\n",
      "Requirement already satisfied: deepl in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langchain-teddynote) (1.19.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.13.1)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.2)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.7.6)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.31.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.6.6)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.19.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.20.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.66.5)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (6.4.5)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.66.2)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.2.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.12.5)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (31.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.10.7)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.27.2)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (13.9.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from fastapi<1,>=0.95.2->langchain-chroma) (0.38.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_text_splitters) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_text_splitters) (24.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: kiwipiepy-model<0.19,>=0.18 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from kiwipiepy->langchain-teddynote) (0.18.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from konlpy->langchain-teddynote) (1.5.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from konlpy->langchain-teddynote) (5.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from openai->langchain-teddynote) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from openai->langchain-teddynote) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from openai->langchain-teddynote) (0.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from openai->langchain-teddynote) (1.3.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from pdf2image->langchain-teddynote) (10.4.0)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.53.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from pinecone-client[grpc]->langchain-teddynote) (1.65.0)\n",
      "Requirement already satisfied: lz4>=3.1.3 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from pinecone-client[grpc]->langchain-teddynote) (4.3.3)\n",
      "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from pinecone-client[grpc]->langchain-teddynote) (1.1.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from pinecone-client[grpc]->langchain-teddynote) (0.0.7)\n",
      "Requirement already satisfied: protobuf<5.0,>=4.25 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from pinecone-client[grpc]->langchain-teddynote) (4.25.5)\n",
      "Requirement already satisfied: protoc-gen-openapiv2<0.0.2,>=0.0.1 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from pinecone-client[grpc]->langchain-teddynote) (0.0.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.6.5 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from pinecone-text->langchain-teddynote) (3.9.1)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.25.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from pinecone-text->langchain-teddynote) (2.32.0.20240914)\n",
      "Requirement already satisfied: wget<4.0,>=3.2 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from pinecone-text->langchain-teddynote) (3.2)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.4.6)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain_text_splitters) (3.0.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.35.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.9)\n",
      "Requirement already satisfied: click in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from nltk<4.0.0,>=3.6.5->pinecone-text->langchain-teddynote) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from nltk<4.0.0,>=3.6.5->pinecone-text->langchain-teddynote) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from nltk<4.0.0,>=3.6.5->pinecone-text->langchain-teddynote) (2024.9.11)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (24.3.25)\n",
      "Requirement already satisfied: sympy in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.13.3)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.4.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.27.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.48b0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.48b0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.48b0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (75.1.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.25.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.6.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.24.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (13.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.9)\n",
      "Requirement already satisfied: filelock in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2024.9.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.20.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.1.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.5.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\david\\desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet bs4 newspaper3k lxml_html_clean python-dotenv pymysql mysql-connector-python sqlalchemy\n",
    "\n",
    "%pip install langchain_text_splitters langchain-community langchain langchain-chroma langchain-teddynote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade newspaper3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.llms import GPT4All\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.callbacks import StreamingStdOutCallbackHandler\n",
    "from newspaper import Article\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.schema import Document\n",
    "from sqlalchemy import create_engine, MetaData, Table, select, Column, Integer, String, Text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import datetime\n",
    "import time\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "CLIENT_ID = os.getenv(\"NAVER_CLIENT_ID\")\n",
    "CLIENT_SECRET = os.getenv(\"NAVER_CLIENT_SECRET\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_USERNAME = os.getenv(\"DB_USERNAME\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_SCHEME = os.getenv(\"DB_SCHEME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_naver_news(query, display=5, start=1, sort='sim'):\n",
    "    url = \"https://openapi.naver.com/v1/search/news.json\"\n",
    "    headers = {\n",
    "        \"X-Naver-Client-Id\": CLIENT_ID,\n",
    "        \"X-Naver-Client-Secret\": CLIENT_SECRET\n",
    "    }\n",
    "    params = {\n",
    "        \"query\": query,  # 검색어\n",
    "        \"display\": display,  # 가져올 결과 수\n",
    "        \"start\": start,  # 검색 시작 위치\n",
    "        \"sort\": sort  # 정렬 기준: date(날짜순), sim(유사도순)\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json() \n",
    "    else:\n",
    "        print(\"Error:\", response.status_code)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "RAG\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"RAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f'mysql+pymysql://{DB_USERNAME}:{DB_PASSWORD}@{DB_HOST}/{DB_SCHEME}')\n",
    "\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "metadata = MetaData()\n",
    "\n",
    "stock_table = Table('STOCK', metadata, autoload_with=engine)\n",
    "\n",
    "stmt = select(stock_table.c.STOCK_ID, stock_table.c.STOCK_NAME)\n",
    "\n",
    "result = session.execute(stmt)\n",
    "\n",
    "stock_list = [(row[0], row[1]) for row in result]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\AppData\\Local\\Temp\\ipykernel_39800\\797968463.py:1: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "class News(Base):\n",
    "    __tablename__ = 'NEWS'\n",
    "    news_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    stock_id = Column(Integer, nullable=False)\n",
    "    title = Column(String(20), nullable=True)\n",
    "    content = Column(Text, nullable=True)\n",
    "    link = Column(String(100), nullable=True)\n",
    "    image = Column(String(100), nullable=True)\n",
    "\n",
    "engine = create_engine(f'mysql+pymysql://{DB_USERNAME}:{DB_PASSWORD}@{DB_HOST}/{DB_SCHEME}')\n",
    "\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "metadata = MetaData()\n",
    "\n",
    "def save_to_database(news_data):\n",
    "    try:\n",
    "        for news_item in news_data:\n",
    "            data = News(\n",
    "                stock_id=news_item['stock_id'],\n",
    "                title=news_item['title'],\n",
    "                link=news_item['link'],\n",
    "                content=news_item['content'],\n",
    "                image=news_item['image']\n",
    "            )\n",
    "            session.add(data)\n",
    "\n",
    "        session.commit()\n",
    "    except Exception as e:\n",
    "        session.rollback() \n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_news_data(news_data_list, docs, result_list):\n",
    "  print(\"start\")\n",
    "  for news_item in news_data_list:\n",
    "    stock_id = news_item['stock_id']\n",
    "    for news_url in news_item['news_url_list']:\n",
    "      if (news_url.startswith(\"https://n.news.naver.com\") == False):\n",
    "        continue\n",
    "      response = requests.get(news_url)\n",
    "      html_content = response.content\n",
    "\n",
    "      soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "      title = soup.find(\"div\", class_=\"media_end_head_title\").get_text(strip=True)\n",
    "      content = soup.find(\"div\", class_=\"newsct_article _article_body\").get_text(strip=True)\n",
    "      # publish_date = soup.find(\"span\", class_=\"media_end_head_info_datestamp_time\").get_text(strip=True)\n",
    "      image = soup.find(\"img\")['data-src']\n",
    "      # publisher = soup.find(\"img\", class_=\"media_end_head_top_logo_img\")['title']\n",
    "\n",
    "      result_list.append({\n",
    "        'stock_id': stock_id,\n",
    "        'title': title,\n",
    "        'content': content,\n",
    "        'link': news_url,\n",
    "        # 'publish_date': publish_date,\n",
    "        'image': image\n",
    "      })\n",
    "\n",
    "      doc_content = title + \"\\n\" + content\n",
    "      doc = Document(page_content=doc_content)\n",
    "      docs.append(doc)\n",
    "    # else:\n",
    "    #   article = Article(news_url, language = 'ko') \n",
    "\n",
    "    #   article.download()\n",
    "    #   article.parse()\n",
    "    #   title = article.title\n",
    "    #   text = article.text\n",
    "    #   date = article.publish_date\n",
    "    #   image_url = article.top_image\n",
    "\n",
    "    #   doc_content = title + \"\\n\" + text\n",
    "    #   doc = Document(page_content=doc_content)\n",
    "    #   docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "now saving...\n",
      "start\n",
      "55 news saved\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "now saving...\n",
      "start\n",
      "63 news saved\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "now saving...\n",
      "start\n",
      "57 news saved\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "now saving...\n",
      "start\n",
      "58 news saved\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "now saving...\n",
      "start\n",
      "74 news saved\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "now saving...\n",
      "start\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnow saving...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m result_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 21\u001b[0m \u001b[43mparse_news_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnews_data_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m save_to_database(result_list)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(result_list)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m news saved\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[44], line 11\u001b[0m, in \u001b[0;36mparse_news_data\u001b[1;34m(news_data_list, docs, result_list)\u001b[0m\n\u001b[0;32m      8\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(news_url)\n\u001b[0;32m      9\u001b[0m html_content \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m---> 11\u001b[0m soup \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhtml_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhtml.parser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m title \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedia_end_head_title\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mget_text(strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m content \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnewsct_article _article_body\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mget_text(strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\David\\Desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\Lib\\site-packages\\bs4\\__init__.py:335\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39minitialize_soup(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 335\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    336\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\David\\Desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\Lib\\site-packages\\bs4\\__init__.py:478\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;66;03m# Convert the document to Unicode.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m--> 478\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;66;03m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendData()\n",
      "File \u001b[1;32mc:\\Users\\David\\Desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\Lib\\site-packages\\bs4\\builder\\_htmlparser.py:380\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.feed\u001b[1;34m(self, markup)\u001b[0m\n\u001b[0;32m    378\u001b[0m parser\u001b[38;5;241m.\u001b[39msoup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoup\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m     parser\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;66;03m# html.parser raises AssertionError in rare cases to\u001b[39;00m\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;66;03m# indicate a fatal problem with the markup, especially\u001b[39;00m\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;66;03m# when there's an error in the doctype declaration.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\html\\parser.py:111\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03mCall this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03mas you want (may include '\\n').\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m+\u001b[39m data\n\u001b[1;32m--> 111\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgoahead\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\html\\parser.py:171\u001b[0m, in \u001b[0;36mHTMLParser.goahead\u001b[1;34m(self, end)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m startswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m, i):\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m starttagopen\u001b[38;5;241m.\u001b[39mmatch(rawdata, i): \u001b[38;5;66;03m# < + letter\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m         k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_starttag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m startswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</\u001b[39m\u001b[38;5;124m\"\u001b[39m, i):\n\u001b[0;32m    173\u001b[0m         k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_endtag(i)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\html\\parser.py:338\u001b[0m, in \u001b[0;36mHTMLParser.parse_starttag\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_startendtag(tag, attrs)\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 338\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_starttag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCDATA_CONTENT_ELEMENTS:\n\u001b[0;32m    340\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_cdata_mode(tag)\n",
      "File \u001b[1;32mc:\\Users\\David\\Desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\Lib\\site-packages\\bs4\\builder\\_htmlparser.py:137\u001b[0m, in \u001b[0;36mBeautifulSoupHTMLParser.handle_starttag\u001b[1;34m(self, name, attrs, handle_empty_element)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m#print(\"START\", name)\u001b[39;00m\n\u001b[0;32m    136\u001b[0m sourceline, sourcepos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetpos()\n\u001b[1;32m--> 137\u001b[0m tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_starttag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msourceline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msourceline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43msourcepos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msourcepos\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tag \u001b[38;5;129;01mand\u001b[39;00m tag\u001b[38;5;241m.\u001b[39mis_empty_element \u001b[38;5;129;01mand\u001b[39;00m handle_empty_element:\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m# Unlike other parsers, html.parser doesn't send separate end tag\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;66;03m# events for empty-element tags. (It's handled in\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;66;03m# don't want handle_endtag() to cross off any previous end\u001b[39;00m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;66;03m# events for tags of this name.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_endtag(name, check_already_closed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\David\\Desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\Lib\\site-packages\\bs4\\__init__.py:742\u001b[0m, in \u001b[0;36mBeautifulSoup.handle_starttag\u001b[1;34m(self, name, namespace, nsprefix, attrs, sourceline, sourcepos, namespaces)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Called by the tree builder when a new tag is encountered.\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \n\u001b[0;32m    726\u001b[0m \u001b[38;5;124;03m:param name: Name of the tag.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;124;03mdon't call handle_endtag.\u001b[39;00m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;66;03m# print(\"Start tag %s: %s\" % (name, attrs))\u001b[39;00m\n\u001b[1;32m--> 742\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendData\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtagStack) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m    746\u001b[0m          \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only\u001b[38;5;241m.\u001b[39msearch_tag(name, attrs))):\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\David\\Desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\Lib\\site-packages\\bs4\\__init__.py:616\u001b[0m, in \u001b[0;36mBeautifulSoup.endData\u001b[1;34m(self, containerClass)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtagStack) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    612\u001b[0m        (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[0;32m    613\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only\u001b[38;5;241m.\u001b[39msearch(current_data)):\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 616\u001b[0m containerClass \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstring_container\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontainerClass\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    617\u001b[0m o \u001b[38;5;241m=\u001b[39m containerClass(current_data)\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobject_was_parsed(o)\n",
      "File \u001b[1;32mc:\\Users\\David\\Desktop\\projects\\please_give_me_assets\\stock-report-data-generator\\gpt4all\\Lib\\site-packages\\bs4\\__init__.py:527\u001b[0m, in \u001b[0;36mBeautifulSoup.string_container\u001b[1;34m(self, base_class)\u001b[0m\n\u001b[0;32m    524\u001b[0m container \u001b[38;5;241m=\u001b[39m base_class \u001b[38;5;129;01mor\u001b[39;00m NavigableString\n\u001b[0;32m    526\u001b[0m \u001b[38;5;66;03m# There may be a general override of NavigableString.\u001b[39;00m\n\u001b[1;32m--> 527\u001b[0m container \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melement_classes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontainer\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;66;03m# On top of that, we may be inside a tag that needs a special\u001b[39;00m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# container class.\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstring_container_stack \u001b[38;5;129;01mand\u001b[39;00m container \u001b[38;5;129;01mis\u001b[39;00m NavigableString:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "news_data_list = []\n",
    "\n",
    "for stock_id, stock_name in stock_list:\n",
    "  result = search_naver_news(stock_name)\n",
    "\n",
    "  news_url_list = []\n",
    "  all_splits = []\n",
    "\n",
    "  if result:\n",
    "    for idx, item in enumerate(result['items']):\n",
    "      news_url_list.append(item['link'])\n",
    "\n",
    "  news_data_list.append({\n",
    "    'stock_id' : stock_id,\n",
    "    'news_url_list' : news_url_list\n",
    "  })\n",
    "  \n",
    "  if(len(news_data_list) >= 50):\n",
    "    print(\"now saving...\")\n",
    "    result_list = []\n",
    "    parse_news_data(news_data_list, all_splits, result_list)\n",
    "    save_to_database(result_list)\n",
    "    print(f'{len(result_list)} news saved')\n",
    "    news_data_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "for news_url in news_data:\n",
    "    article = Article(news_url, language = 'ko') \n",
    "\n",
    "    article.download()\n",
    "    print(news_url)\n",
    "    article.parse()\n",
    "    title = article.title\n",
    "    text = article.text\n",
    "    date = article.publish_date\n",
    "    image_url = article.top_image\n",
    "\n",
    "    doc_content = title + \"\\n\" + text\n",
    "    doc = Document(page_content=doc_content)\n",
    "    docs = [doc] \n",
    "\n",
    "    # add_to_verctor_db(text_splitter, docs)\n",
    "    print(f\"URL: {news_url}\\n {title}\\n {text}\\n {date}\\n{image_url}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_splits = []\n",
    "\n",
    "\n",
    "for news_url in news_data:\n",
    "    if news_url.startswith(\"https://n.news.naver.com\"):\n",
    "        # 각 뉴스 URL에 대해 WebBaseLoader를 설정합니다.\n",
    "        loader = WebBaseLoader(\n",
    "            web_paths=(news_url,),\n",
    "            bs_kwargs=dict(\n",
    "                parse_only=bs4.SoupStrainer(\n",
    "                    \"div\",\n",
    "                    attrs={\"class\": [\"newsct_article _article_body\", \"media_end_head_title\"]},\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "        article = Article(news_url, language = 'ko') \n",
    "\n",
    "        article.download()\n",
    "        article.parse()\n",
    "\n",
    "        image_url = article.top_image\n",
    "        docs = loader.load()\n",
    "        print('docs :{docs}\\n image_url :{image_url}')\n",
    "    else:\n",
    "\n",
    "        article = Article(news_url, language = 'ko') \n",
    "\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        title = article.title\n",
    "        text = article.text\n",
    "        date = article.publish_date\n",
    "        image_url = article.top_image\n",
    "\n",
    "        doc_content = title + \"\\n\" + text\n",
    "        doc = Document(page_content=doc_content)\n",
    "        docs = [doc] \n",
    "\n",
    "    print(f\"URL: {news_url} {image_url}\")\n",
    "    \n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    all_splits.extend(splits)\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=GPT4AllEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# prompt = PromptTemplate.from_template(\n",
    "#     \"\"\"당신은 질문-답변(Question-Answering)을 수행하는 친절한 AI 어시스턴트입니다. 당신의 임무는 주어진 문맥(context) 에서 주어진 질문(question) 에 답하는 것입니다.\n",
    "# 검색된 다음 문맥(context) 을 사용하여 질문(question) 에 답하세요. 만약, 주어진 문맥(context) 에서 답을 찾을 수 없다면, 답을 모른다면 `주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다` 라고 답하세요.\n",
    "# 한글로 답변해 주세요. 단, 기술적인 용어나 이름은 번역하지 않고 그대로 사용해 주세요.\n",
    "\n",
    "# #Question: \n",
    "# {question} \n",
    "\n",
    "# #Context: \n",
    "# {context} \n",
    "\n",
    "# #Answer:\"\"\"\n",
    "# )\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"당신은 최신 금융 동향을 분석하고 제공하는 친절한 AI 어시스턴트입니다. 당신의 임무는 주어진 문맥(context)을 바탕으로 금융 시장에 대한 동향을 전달하는 것입니다.\n",
    "검색된 다음 문맥(context)을 사용하여 최신 금융 시장 동향을 요약해 주세요. 만약, 주어진 문맥(context)에서 동향을 찾을 수 없다면, `주어진 정보에서 금융 시장 동향에 대한 정보를 찾을 수 없습니다`라고 답하세요.\n",
    "한글로 답변해 주세요. 단, 기술적인 용어나 이름은 번역하지 않고 그대로 사용해 주세요.\n",
    "\n",
    "#문맥(Context): \n",
    "{context} \n",
    "\n",
    "#금융 시장 동향 요약:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEVE_Korean_Instruct = \"C:/Users/David/AppData/Local/nomic.ai/GPT4All/EEVE-Korean-Instruct-10.8B-v1.0-Q4_0.gguf\"  # 원하는 로컬 파일 경로로 대체하세요\n",
    "gpt4all_falcon = \"C:/Users/David/AppData/Local/nomic.ai/GPT4All/gpt4all-falcon-newbpe-q4_0.gguf\"\n",
    "llama3_8b =\"C:/Users/David/AppData/Local/nomic.ai/GPT4All/Meta-Llama-3-8B-Instruct.Q4_0.gguf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GPT4All(\n",
    "    model=gpt4all_falcon,\n",
    "    # backend=\"gpu\",  # GPU 설정\n",
    "    streaming=True,  # 스트리밍 설정\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],  # 콜백 설정\n",
    ")\n",
    "\n",
    "# 체인 생성\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = rag_chain.stream(\"금융 시장 동향을 요약해주세요.\")\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm(\"한국어로 답변할 수 있습니다?\")\n",
    "\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt4all",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
